{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import boston_housing\n",
    "(train_data,train_targets),(test_data,test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(train_data)\n",
    "X_test = sc.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.27224633, -0.48361547, -0.43576161, ...,  1.14850044,\n",
       "         0.44807713,  0.8252202 ],\n",
       "       [-0.40342651,  2.99178419, -1.33391162, ..., -1.71818909,\n",
       "         0.43190599, -1.32920239],\n",
       "       [ 0.1249402 , -0.48361547,  1.0283258 , ...,  0.78447637,\n",
       "         0.22061726, -1.30850006],\n",
       "       ...,\n",
       "       [-0.40202987,  0.99079651, -0.7415148 , ..., -0.71712291,\n",
       "         0.07943894, -0.67776904],\n",
       "       [-0.17292018, -0.48361547,  1.24588095, ..., -1.71818909,\n",
       "        -0.98764362,  0.42083466],\n",
       "       [-0.40422614,  2.04394792, -1.20161456, ..., -1.30866202,\n",
       "         0.23317118, -1.15392266]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.8040301 , -0.50784934,  0.96960877, ...,  0.90513041,\n",
       "        -4.27829517,  2.51324773],\n",
       "       [-0.55530596, -0.50784934, -0.17801704, ..., -0.28485844,\n",
       "         0.3909446 ,  0.58604286],\n",
       "       [-0.56808398, -0.50784934, -0.86176938, ...,  0.90513041,\n",
       "         0.41570668, -0.38506427],\n",
       "       ...,\n",
       "       [-0.23539182, -0.50784934,  1.17955762, ..., -1.82192738,\n",
       "         0.32313459, -1.55879807],\n",
       "       [-0.5113909 , -0.50784934, -0.71849348, ..., -0.48318992,\n",
       "         0.34967446, -0.38956708],\n",
       "       [-0.03148414, -0.50784934,  1.17955762, ..., -1.82192738,\n",
       "        -1.57465677, -0.3745577 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape = (train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation = 'relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(loss = 'mse', optimizer = 'rmsprop', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "num_val_samples = len(train_data)//k\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples:(i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples : (i+1)*num_val_samples]\n",
    "    partial_train_data = np.concatenate([train_data[:i*num_val_samples],\n",
    "                                        train_data[(i+1)*num_val_samples:]], axis = 0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],\n",
    "                                       train_targets[(i+1)*num_val_samples:]], axis = 0)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data,partial_train_targets,\n",
    "             epochs = num_epochs,batch_size=1,verbose=0)\n",
    "    val_mse,val_mae = model.evaluate(val_data,val_targets,verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.211258888244629, 3.368643045425415, 3.9292056560516357]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.836369196573893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mean_absolute_error'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-25b9d8615c2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     history = model.fit(partial_train_data,partial_train_targets,\n\u001b[0;32m     20\u001b[0m              epochs = num_epochs,batch_size=1,verbose=0, validation_data=(val_data,val_targets))\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mmae_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_absolute_error'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mall_mae_histories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmae_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mean_absolute_error'"
     ]
    }
   ],
   "source": [
    "k = 4\n",
    "num_val_samples = len(train_data)//k\n",
    "\n",
    "num_epochs = 500\n",
    "all_mae_histories = []\n",
    "\n",
    "\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples:(i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples : (i+1)*num_val_samples]\n",
    "    partial_train_data = np.concatenate([train_data[:i*num_val_samples],\n",
    "                                        train_data[(i+1)*num_val_samples:]], axis = 0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate([train_targets[:i * num_val_samples],\n",
    "                                       train_targets[(i+1)*num_val_samples:]], axis = 0)\n",
    "    \n",
    "    model = build_model()\n",
    "    history = model.fit(partial_train_data,partial_train_targets,\n",
    "             epochs = num_epochs,batch_size=1,verbose=0, validation_data=(val_data,val_targets))\n",
    "    mae_history = history.history['mean_absolute_error']\n",
    "    all_mae_histories.append(mae_history)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
